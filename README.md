ğŸš€ Capstone Project: Serverless RDS to S3 Data Export Pipeline
ğŸ“Œ Project Overview

This project implements a serverless, scheduled data ingestion pipeline that extracts data from an Amazon RDS database and exports it as CSV files into Amazon S3 using modern AWS-native services.

The solution replaces legacy approaches such as EC2 cron jobs or AWS Data Pipeline with a **modern, secure, and cost-efficient serverless architecture** using AWS native services.

---

## â­ Key Points

- AWS Lambda runs inside the same VPC as Amazon RDS for secure, private connectivity  
- Database credentials are retrieved securely from AWS Secrets Manager  
- Output files are generated as timestamped CSV files and stored in Amazon S3  

---

## ğŸ§© Problem Statement

Traditional RDS data exports often rely on:
- Long-running EC2 instances
- Deprecated AWS Data Pipeline
- Hard-coded credentials
- High operational and maintenance overhead

These approaches increase cost, security risk, and operational complexity.

---

## ğŸ› ï¸ Technologies Used

- AWS Lambda â€“ Serverless compute for data extraction
- Amazon EventBridge â€“ Time-based scheduling
- Amazon RDS â€“ Source database (MySQL / PostgreSQL)
- Amazon S3 â€“ CSV storage
- AWS Secrets Manager â€“ Secure credential storage
- Amazon CloudWatch â€“ Logs and monitoring
- IAM, VPC, Security Groups

---

## ğŸ” Security Design

- Database credentials stored in AWS Secrets Manager
- IAM roles follow the principle of least privilege
- Lambda runs inside a private VPC
- RDS is not publicly accessible
- No secrets are hard-coded in the source code

---

## ğŸ“„ Data Flow

1. EventBridge triggers the Lambda function based on schedule
2. Lambda retrieves credentials from Secrets Manager
3. Lambda connects to RDS inside the VPC
4. SQL query runs on the target table
5. Result set is converted into CSV format
6. CSV file is uploaded to Amazon S3 with a timestamped name
7. Logs are written to CloudWatch

---

## ğŸ“¦ Repository Structure

serverless-rds-to-s3-pipeline/
â”œâ”€â”€ README.md
â”œâ”€â”€ lambda/
â”‚ â”œâ”€â”€ lambda_function.py
â”‚ â””â”€â”€ requirements.txt
â”œâ”€â”€ docs/
â”‚ â””â”€â”€ architecture.md
â””â”€â”€ .gitignore

---

## ğŸ“¤ Sample Output

s3://my-rds-export-bucket/rds_exports/
â”œâ”€â”€ employees_20260222_101200.csv
â”œâ”€â”€ employees_20260222_221200.csv

---

## ğŸ’° Cost Analysis

| Service | Cost Impact |
|---------|-------------|
| EventBridge | ~$1 per million events |
| Lambda | Pay per execution (milliseconds) |
| S3 | Pennies for small CSV files |
| CloudWatch Logs | Negligible |
| RDS | Existing hourly cost |

**Total cost:** Effectively near zero for low-frequency schedules

---

## âš ï¸ Challenges Faced

- **Issue:** Lambda failed with an invalid S3 bucket name
- **Root Cause:** Trailing whitespace in the bucket name
- **Resolution:** Sanitized environment variables and validated S3 naming rules

---

## ğŸ“ˆ Future Enhancements

- Incremental exports using `updated_at`
- Exactly-once delivery using DynamoDB
- SNS alerts on failures
- Glue + Athena integration for analytics
- Terraform / IaC automation
- CDC-based near real-time ingestion

---

## ğŸ§  Key Learnings

- Serverless networking with VPC
- IAM least-privilege role design
- Secure secrets management
- Event-driven architectures
- Debugging AWS SDK validation errors
- Cost-optimized cloud solutions

---

## ğŸ¯ Solution

Design and implement a **fully serverless pipeline** that:
- Runs on a fixed schedule
- Securely connects to RDS inside a VPC
- Exports relational data as CSV
- Stores output in Amazon S3
- Scales automatically
- Incurs near-zero cost when idle

---

## ğŸ Conclusion

This project demonstrates a real-world, production-ready serverless data pipeline, showcasing strong DevOps and AWS cloud architecture skills suitable for interviews and portfolio presentation.

