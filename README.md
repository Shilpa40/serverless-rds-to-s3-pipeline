ğŸš€ Capstone Project: Serverless RDS to S3 Data Export Pipeline
ğŸ“Œ Project Overview

This project implements a serverless, scheduled data ingestion pipeline that extracts data from an Amazon RDS database and exports it as CSV files into Amazon S3 using modern AWS-native services.

The solution replaces deprecated AWS Data Pipelineâ€“based workflows with a Lambda + EventBridge architecture that is cost-efficient, secure, and production-ready.

ğŸ§© Problem Statement

Traditional RDS data exports often rely on:

Long-running EC2 instances

Deprecated AWS Data Pipeline

Hard-coded database credentials

High operational overhead

These approaches increase cost, security risk, and maintenance effort.

ğŸ¯ Solution

Design and implement a fully serverless pipeline that:

Runs on a fixed schedule (every 5 minutes / 12 hours)

Securely connects to RDS inside a VPC

Exports relational data as CSV

Stores output in S3

Scales automatically

Costs nearly nothing when idle

ğŸ—ï¸ Architecture
Amazon EventBridge (schedule)
        â†“
AWS Lambda (Python)
        â†“
Amazon RDS (MySQL / PostgreSQL)
        â†“
Amazon S3 (CSV exports)
ğŸ› ï¸ Technologies Used

AWS Lambda â€“ Data extraction and export logic

Amazon EventBridge â€“ Time-based orchestration

Amazon RDS â€“ Source database

Amazon S3 â€“ CSV storage

AWS Secrets Manager â€“ Secure credential storage

Amazon CloudWatch â€“ Logging & monitoring

IAM, VPC, Security Groups

âš™ï¸ Key Features

âœ… Fully serverless (no EC2, no cron servers)

âœ… Secure credential handling (no plaintext secrets)

âœ… Runs inside VPC for private RDS access

âœ… Scheduled execution using EventBridge

âœ… Automatic CSV generation and upload

âœ… Extremely low cost (pay-per-use)

âœ… Production-ready IAM least privilege model

ğŸ” Security Design

Database credentials stored in Secrets Manager

Lambda execution role follows least privilege

RDS access restricted via security groups

No public DB access

No hard-coded secrets in code

ğŸ“„ Data Flow

EventBridge triggers Lambda based on schedule

Lambda retrieves DB credentials from Secrets Manager

Lambda connects to RDS inside VPC

SQL query runs on target table

Result set is converted to CSV

CSV file is uploaded to S3 with timestamped name

Execution logs written to CloudWatch

ğŸ“¦ Sample Output
s3://my-rds-export-bucket/rds_exports/
 â”œâ”€â”€ employees_20260222_101200.csv
 â”œâ”€â”€ employees_20260222_221200.csv
ğŸ’° Cost Analysis
Service	Cost Impact
EventBridge	~$0.000001 per run
Lambda	~$0.000005 per execution
S3	Few MBs â†’ negligible
CloudWatch Logs	Negligible
RDS	Existing hourly cost

Total: Effectively free for low-frequency schedules.

âš ï¸ Challenges Faced & Fixes
Issue: Lambda could not upload to S3

Cause: Trailing whitespace in bucket name
Fix: Sanitized environment variables using .strip() and validated S3 naming rules

ğŸ“ˆ Enhancements (Future Scope)

Incremental exports using updated_at

Exactly-once processing using DynamoDB state tracking

SNS alerts on failure

Glue/Athena integration for analytics

Terraform/IaC automation

CDC-style near real-time ingestion

ğŸ§  Learnings

Deep understanding of serverless networking with VPC

Practical IAM role design

Secrets Manager integration

Cost-optimized event-driven architectures

Debugging AWS SDK validation errors

Designing production-grade pipelines without EC2

ğŸ Conclusion

This project demonstrates a modern DevOps + Cloud data engineering workflow, replacing legacy AWS services with a scalable, secure, and cost-effective serverless solution.

It is suitable for:

Production workloads

Cloud/DevOps interviews

Real-world data export automation
